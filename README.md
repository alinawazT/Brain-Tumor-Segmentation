# Brain-Tumor-Segmentation
Similar to the standard UNET, the proposed framework is composed of encoder and decoder. The encoder part is standard VGG19 which is used to extract features from MR image meanwhile the decoder part uses the output of encoder VGG19 to segment the image by upsampling the feature maps.
## Datasets
For the evaluation of proposed frameworks, two types of datasets were used. Specifically, for segmentation task the BRATS20 was used which consists of 371 images files and each file is composed of five subfiles out which four files are MRI modalities of the individual patients and one file is the target mask of the individual patient. T1, T2, T2* and Attenuated Inversion Recovery (FLAIR) weighted mages are most common modalities of MRI utilizes in this dataset. TI weighted mages is generated by using short Repetition Time (TR) and Time to Echo (TE) while T2 weighted mages is generated by using longer TR and TE than T2 similarly, FLAIR weighted images are variant of the T2 which is generated by using longer TR and TE than T2 and output mask is the manual segmentation of each patient tumor. Similarly, for survival prediction, BRATS20 survival info was used. The datasets are composed of 371 entities of individual patient which are pseudo identifier of the imaging data. The survival info datasets include patients age and resurrection status of the patients
## VGG19
VGG19 is the commonly used CNN composed of 19 layers. Out of 19 layers, 16 are convolutional layers, 5 max-pool layers, 3 fully connected layers and 1 SoftMax layers. The architecture of VGG19 is simple that follows the six steps process.
•	First the image is provided as input to the architecture usually image of the shape (224, 224, 3) is provided as input.
•	Then, kernel of size (3, 3) was applied to discover the underlying patterns of the image.
•	Padding was used preserve the resolution of the image
•	Pooling was applied to reduce the dimension of image
•	The output of the layers is usually linear therefore, fully connected layer was applied to transform linear output into non-linear output
•	Finally, SoftMax layer is applied to predict the probability distribution of the multiple classes
The training of VGG19 from scratch is tedious and complex task therefore, nowadays a pretrained VGG19 is often used. A pretrained VGG19 is usually trained on larger datasets i.e., ImageNet therefore the learning of new and complex patterns becomes simple and efficient.
## Feature Extraction
The BRATS'20 overall survival info datasets consist of 371 entities having 4 columns and 3 labels. From datasets age, amount of edema, amount of necrotic and amount of enhancing tumor were extracted and utilized for survival prediction task.
## Normalization
All the four columns of the datasets contain the values ranges from positive infinity to negative infinity. In this case, it difficult for learning algorithm to find the hidden pattern in the datasets therefore, in this paper we use Minmax normalization to limit the values between 0 and 1. It can easily be performed by using MinMaxScaler() function of Scikit Learn preprocessing in python. Minmax normalization preserves the linear transformation of the attributes. The equation shows that mini is the minimum value of the attribute and maxi is the maximum value of the attribute and vi is the attribute value whose normalization is to be performed and vi is the final normalized value.
## Ensemble Classifier
Ensemble learning is a type of machine learning technique that combines multiple machine learning models to produce optimal prediction results. To further improve the performance of prediction, an ensemble of random forest Naïve Bayes (NB) is performed by applying hard voting classifier that means we predict class labels by majority rule voting instead of probability based. Random forest is prominent ensemble model that is the combination of multiple decision tree. Decision tree is the most powerful and important algorithm for predictive modeling machine learning. Decision tree is known by its modern name Classification and Regression Tree (CART). Therefore, it can be used to solve both classification and regression problems. The decision tree can perform classification by sorting down the training data from top (root) node to the bottom (leaf) node of the tree. Each instance is classified by starting from the root node of the tree then testing the instance specified by the node and moving down till the leaf node. This process is repeated for all subtree rooted at the new nodes. Meanwhile, NB is another supervised machine learning algorithm use to classify data into predefined classes. It simply did this by finding the probability that something will happen given that something else has already happened. Therefore, in this task ensemble voting classifier of random forest and NB was applied to classify the patient survival into short, medium and long survival classes.
